{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68345c05",
   "metadata": {},
   "source": [
    "# CS 639 - Foundations of Data Science\n",
    "\n",
    "# Discussion 03 (Estimating variance and Set Balancing Problem)\n",
    "\n",
    "In this dicussion session, we are going to cover more examples of using Hoeffding Bound, including taking a deeper dive into a practical application.\n",
    "\n",
    "* Bounding the population variance from n i.i.d. samples X_i: Define Y_i = (X_i - E(X))^2 then apply Hoeffding bound.\n",
    "* The set balancing problem: How to apply the mathematical tools we learnt in a real-life problem to get useful intuitions. (Section 4.4 from M. Mitzenmacher, E. Upfal: Probability and Computing)\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c85f74",
   "metadata": {},
   "source": [
    "## Estimating Variance\n",
    "\n",
    "Given $n$ samples $X_1, \\cdots, X_n$ where $X_i$'s are drawn independently from a bounded random variable $X$, we would like to say something about $X$ based on the samples we observe. We have seen in class that we can give a confidence bound for the expectated value of $X$ by using an estimator $S_n /n$ for the mean then by applying Hoeffding bound. One less obvious thing we can also do is to give a similar estimate for the variance of $X$, if we know the true mean $\\mathbb{E}[X]$.\n",
    "\n",
    "The trick is to obverse that the variance of $X$ is itself an expectation. Recall that the variance of $X$ is defined as $\\mathrm{Var} [X] = \\mathbb{E} [(X - \\mathbb{E}[X])^2]$, we can see that if we define a new random variable $Y = (X - \\mathbb{E}[X])^2$, then $\\mathrm{Var} [X] = \\mathbb{E} [Y]$. Then we can apply Hoeffding's inequality to give a confidence interval for the true variance of $X$ based on the empirical variance from $X_1, \\cdots, X_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7712e7",
   "metadata": {},
   "source": [
    "In particular, we will generate $Y_1,\\cdots, Y_n$ where $Y_i = (X_i - \\mathbb{E}[X])^2$ for $i \\in [n]$.\n",
    "* (Boundedness) First, let us argue that $Y_i$'s are bounded: Suppose $X \\in [a, b]$ for some $a, b \\in \\mathbb{R}$, then we know $Y \\in [a', b']$ where $a' = 0$ and $b' = (b-a)^2$ (why?).\n",
    "* (Independence) Next, let us argue that $Y_i$'s are generated independently as well. Note that $\\mathbb{E}[X]$ assumed to be a known constant, so we can conclude that $Y_i$'s are independent.\n",
    "\n",
    "Therefore, we can use Hoeffding bound to bound the deviation of $\\frac{1}{n} \\sum_{i=1}^n Y_i$ from the variance of $X$, $\\mathbb{E} [Y]$. Notice that $\\frac{1}{n} \\sum_{i=1}^n Y_i$ is exaclty our empirical variance, and we will denote it as $\\hat{\\sigma}^2_n (X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c59a40",
   "metadata": {},
   "source": [
    "Similar to we have done in the lectures with Hoeffding bound, we get\n",
    "$$\n",
    "  \\mathbb{P} \\left[\\left|\\frac{1}{n} \\sum_{i=1}^n Y_i - \\mathbf{E}[Y] \\right| \\ge t \\right] \\le 2 e^{\\frac{-2nt^2}{(b' - a'\n",
    "  )^2}}.\n",
    "$$\n",
    "\n",
    "Using the values for $a'$ and $b'$ and rewriting the expression using $X$, we get\n",
    "$$\n",
    "  \\mathbb{P} [|\\hat{\\sigma}_n^2 (X) - \\mathrm{Var}[X] | \\ge t ] \\le 2 e^{\\frac{-2nt^2}{(b - a\n",
    "  )^4}}.\n",
    "$$\n",
    "\n",
    "In plain words, we conclude that the probalility that our empirical variance is far away from the population variance with small probaility as the number of sample $n$ scales.\n",
    "\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac74fe7",
   "metadata": {},
   "source": [
    "## Set Balancing Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe4d2c",
   "metadata": {},
   "source": [
    "In many statistical trials, we would like to divide the candidates into two groups: The control group, and the experimental group. Ideally we would like the two groups to be relatively similar in terms of their identifiable features. For example, if we want to conduct medical trials to determine the efficacy of a COVID vaccine, we would want to make sure the age, race, gender and other factors of the two groups are similar. \n",
    "\n",
    "This problem can be formulated mathematically as a Set Balancing Problem. Using the tools we have learnt from class so far, we can actually say something about how good (or bad) we can do without knowing anything about the features of any candidates. Please refer to Section 4.4 from M. Mitzenmacher, E. Upfal: Probability and Computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50190688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
